# ScrapyProject
可分布式爬取智联、拉钩、知乎、京东、淘宝等网站数据，自动登录，集成打码平台
使用scrapy-redis进行数据去重，splash和selenium进行网页渲染
可使用西刺免费IP代理进行IP地址切换
````
环境及依赖包
Python 3.4
````
````
爬取京东项目说明:https://www.cnblogs.com/dukuan/p/8336670.html
````
````
requirement：


appdirs==1.4.3

argh==0.26.2

asn1crypto==0.22.0

attrs==16.3.0

Automat==0.6.0

bcrypt==3.1.4

beautifulsoup4==4.6.0

browsercookie==0.7.2

bs4==0.0.1

cffi==1.10.0

constantly==15.1.0

cryptography==2.1.4

cssselect==1.0.1

Cython==0.25.2

Django==1.11.7

elasticsearch==5.4.0

elasticsearch-dsl==5.3.0

fake-useragent==0.1.7

gevent==1.2.2

greenlet==0.4.12

idna==2.5

incremental==16.10.1

inotify==0.2.8

keyring==10.5.1

lxml==4.1.0

mysqlclient==1.3.10

olefile==0.44

packaging==16.8

paramiko==2.3.1

parsel==1.1.0

pathtools==0.1.2

Pillow==4.1.1

proxies==1.6

pyasn1==0.2.3

pyasn1-modules==0.0.8

pycparser==2.17

pycrypto==2.6.1

PyDispatcher==2.0.5

pymongo==3.6.0

PyMySQL3==0.5

PyNaCl==1.2.0

pyOpenSSL==17.3.0

pyparsing==2.2.0

pypiwin32==219

pyquery==1.2.17

PySocks==1.6.7

pytesseract==0.1.7

python-dateutil==2.6.0

pytz==2017.3

pywin32==221

pywin32-ctypes==0.1.2

PyYAML==3.12

queuelib==1.4.2

redis==2.10.5

requests==2.14.2

retrying==1.3.3

Scrapy==1.3.3

scrapy-crawlera==1.2.4

scrapy-redis==0.6.8

scrapy-splash==0.7.2

scrapyd==1.2.0

scrapyd-client==1.1.0

selenium==3.4.3

service-identity==16.0.0

six==1.10.0

Twisted==17.1.0

urllib3==1.21.1

virtualenv==15.1.0

virtualenvwrapper-win==1.2.4

w3lib==1.18.0

watchdog==0.8.3

zope.interface==4.4.3
````

